{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTsEYdtov6tp"
      },
      "source": [
        "# Beijing Air Quality Forecasting Starter Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "nWkSHhqXrCqF"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "gxW-6b_jrLAL"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "# Ensure train.csv and test.csv are saved in your Google Drive in the same folder.\n",
        "# Replace the file paths below with the actual paths to your dataset.\n",
        "train = pd.read_csv('data/train.csv')\n",
        "test = pd.read_csv('data/test.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRse3uqRrft5"
      },
      "source": [
        "# Explore the training data\n",
        "\n",
        "In this sections explore your dataset with appropiate statistics and visualisations to understand your better. Ensure that you explain output of every code cell and what it entails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "3R74CEBFrYok",
        "outputId": "0e593627-9c80-490c-826e-74e4df4a2249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data Overview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>DEWP</th>\n",
              "      <th>TEMP</th>\n",
              "      <th>PRES</th>\n",
              "      <th>Iws</th>\n",
              "      <th>Is</th>\n",
              "      <th>Ir</th>\n",
              "      <th>datetime</th>\n",
              "      <th>cbwd_NW</th>\n",
              "      <th>cbwd_SE</th>\n",
              "      <th>cbwd_cv</th>\n",
              "      <th>pm2.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.580878</td>\n",
              "      <td>-1.922250</td>\n",
              "      <td>0.443328</td>\n",
              "      <td>-0.441894</td>\n",
              "      <td>-0.069353</td>\n",
              "      <td>-0.137667</td>\n",
              "      <td>2010-01-01 00:00:00</td>\n",
              "      <td>1.448138</td>\n",
              "      <td>-0.732019</td>\n",
              "      <td>-0.522096</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.580878</td>\n",
              "      <td>-2.004228</td>\n",
              "      <td>0.345943</td>\n",
              "      <td>-0.379306</td>\n",
              "      <td>-0.069353</td>\n",
              "      <td>-0.137667</td>\n",
              "      <td>2010-01-01 01:00:00</td>\n",
              "      <td>1.448138</td>\n",
              "      <td>-0.732019</td>\n",
              "      <td>-0.522096</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>-1.580878</td>\n",
              "      <td>-1.922250</td>\n",
              "      <td>0.248559</td>\n",
              "      <td>-0.343514</td>\n",
              "      <td>-0.069353</td>\n",
              "      <td>-0.137667</td>\n",
              "      <td>2010-01-01 02:00:00</td>\n",
              "      <td>1.448138</td>\n",
              "      <td>-0.732019</td>\n",
              "      <td>-0.522096</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>-1.580878</td>\n",
              "      <td>-2.168183</td>\n",
              "      <td>0.248559</td>\n",
              "      <td>-0.280926</td>\n",
              "      <td>-0.069353</td>\n",
              "      <td>-0.137667</td>\n",
              "      <td>2010-01-01 03:00:00</td>\n",
              "      <td>1.448138</td>\n",
              "      <td>-0.732019</td>\n",
              "      <td>-0.522096</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>-1.511594</td>\n",
              "      <td>-2.004228</td>\n",
              "      <td>0.151174</td>\n",
              "      <td>-0.218339</td>\n",
              "      <td>-0.069353</td>\n",
              "      <td>-0.137667</td>\n",
              "      <td>2010-01-01 04:00:00</td>\n",
              "      <td>1.448138</td>\n",
              "      <td>-0.732019</td>\n",
              "      <td>-0.522096</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   No      DEWP      TEMP      PRES       Iws        Is        Ir  \\\n",
              "0   1 -1.580878 -1.922250  0.443328 -0.441894 -0.069353 -0.137667   \n",
              "1   2 -1.580878 -2.004228  0.345943 -0.379306 -0.069353 -0.137667   \n",
              "2   3 -1.580878 -1.922250  0.248559 -0.343514 -0.069353 -0.137667   \n",
              "3   4 -1.580878 -2.168183  0.248559 -0.280926 -0.069353 -0.137667   \n",
              "4   5 -1.511594 -2.004228  0.151174 -0.218339 -0.069353 -0.137667   \n",
              "\n",
              "              datetime   cbwd_NW   cbwd_SE   cbwd_cv  pm2.5  \n",
              "0  2010-01-01 00:00:00  1.448138 -0.732019 -0.522096    NaN  \n",
              "1  2010-01-01 01:00:00  1.448138 -0.732019 -0.522096    NaN  \n",
              "2  2010-01-01 02:00:00  1.448138 -0.732019 -0.522096    NaN  \n",
              "3  2010-01-01 03:00:00  1.448138 -0.732019 -0.522096    NaN  \n",
              "4  2010-01-01 04:00:00  1.448138 -0.732019 -0.522096    NaN  "
            ]
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inspecting the first few rows of the dataset to understand its structure.\n",
        "print(\"Training Data Overview:\")\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-om6hH_RtG8Z",
        "outputId": "8fefc873-d80f-4b45-ead2-89bbfc8d4d62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['No', 'DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir', 'datetime', 'cbwd_NW',\n",
              "       'cbwd_SE', 'cbwd_cv', 'pm2.5'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABAqt0Jztd5s"
      },
      "source": [
        "# Handle missing values\n",
        "\n",
        "\n",
        "- Check the dataset for missing values and decide how to handle them.\n",
        "- In this example, missing values are filled with the mean. You can experiment with other strategies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "u2n29Ge1tami"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding lagged features and engineered features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['hour'] = df_copy.index.hour\n",
            "/tmp/ipykernel_150298/327019887.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['day_of_week'] = df_copy.index.dayofweek\n",
            "/tmp/ipykernel_150298/327019887.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['month'] = df_copy.index.month\n",
            "/tmp/ipykernel_150298/327019887.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['is_weekend'] = (df_copy.index.dayofweek >= 5).astype(int)\n",
            "/tmp/ipykernel_150298/327019887.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['season'] = ((df_copy.index.month % 12 + 3) // 3).map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'})\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
            "/tmp/ipykernel_150298/327019887.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
            "/tmp/ipykernel_150298/327019887.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
            "/tmp/ipykernel_150298/327019887.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
            "/tmp/ipykernel_150298/327019887.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['hour'] = df_copy.index.hour\n",
            "/tmp/ipykernel_150298/327019887.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['day_of_week'] = df_copy.index.dayofweek\n",
            "/tmp/ipykernel_150298/327019887.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['month'] = df_copy.index.month\n",
            "/tmp/ipykernel_150298/327019887.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['is_weekend'] = (df_copy.index.dayofweek >= 5).astype(int)\n",
            "/tmp/ipykernel_150298/327019887.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df_copy['season'] = ((df_copy.index.month % 12 + 3) // 3).map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original features: 217 -> Enhanced features: 217\n",
            "Training data shape: (30652, 1, 217)\n",
            "Target shape: (30652,)\n"
          ]
        }
      ],
      "source": [
        "# Efficient fillna with mean (same as before)\n",
        "train['datetime'] = pd.to_datetime(train['datetime'])\n",
        "test['datetime'] = pd.to_datetime(test['datetime'])\n",
        "train.set_index('datetime', inplace=True)\n",
        "test.set_index('datetime', inplace=True)\n",
        "train.fillna(train.mean(), inplace=True)\n",
        "test.fillna(test.mean(), inplace=True)\n",
        "\n",
        "# Feature Engineering - Add lagged features and other engineered features\n",
        "def add_lagged_features(df, lags=[1, 2, 3, 6, 12, 24]):\n",
        "    \"\"\"Add lagged features for all numeric columns\"\"\"\n",
        "    df_copy = df.copy()\n",
        "    \n",
        "    # Add lagged features\n",
        "    for lag in lags:\n",
        "        for col in df.columns:\n",
        "            if col not in ['pm2.5', 'No']:  # Don't lag target or ID\n",
        "                df_copy[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
        "    \n",
        "    # Add rolling window features\n",
        "    for window in [3, 6, 12, 24]:\n",
        "        for col in df.columns:\n",
        "            if col not in ['pm2.5', 'No']:\n",
        "                df_copy[f'{col}_rolling_mean_{window}'] = df[col].rolling(window=window).mean()\n",
        "                df_copy[f'{col}_rolling_std_{window}'] = df[col].rolling(window=window).std()\n",
        "                df_copy[f'{col}_rolling_max_{window}'] = df[col].rolling(window=window).max()\n",
        "                df_copy[f'{col}_rolling_min_{window}'] = df[col].rolling(window=window).min()\n",
        "    \n",
        "    # Add time-based features\n",
        "    df_copy['hour'] = df_copy.index.hour\n",
        "    df_copy['day_of_week'] = df_copy.index.dayofweek\n",
        "    df_copy['month'] = df_copy.index.month\n",
        "    df_copy['is_weekend'] = (df_copy.index.dayofweek >= 5).astype(int)\n",
        "    df_copy['season'] = ((df_copy.index.month % 12 + 3) // 3).map({1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'})\n",
        "    \n",
        "    # Encode categorical season feature\n",
        "    season_dummies = pd.get_dummies(df_copy['season'], prefix='season')\n",
        "    df_copy = pd.concat([df_copy.drop('season', axis=1), season_dummies], axis=1)\n",
        "    \n",
        "    # Add interaction features (example with key meteorological variables)\n",
        "    if 'TEMP' in df.columns and 'DEWP' in df.columns:\n",
        "        df_copy['temp_dewp_diff'] = df_copy['TEMP'] - df_copy['DEWP']\n",
        "    if 'TEMP' in df.columns and 'PRES' in df.columns:\n",
        "        df_copy['temp_pres_interaction'] = df_copy['TEMP'] * df_copy['PRES']\n",
        "    if 'WSPM' in df.columns and 'TEMP' in df.columns:\n",
        "        df_copy['wind_temp_interaction'] = df_copy['WSPM'] * df_copy['TEMP']\n",
        "    \n",
        "    return df_copy\n",
        "\n",
        "# Apply feature engineering\n",
        "print(\"Adding lagged features and engineered features...\")\n",
        "train = add_lagged_features(train)\n",
        "test = add_lagged_features(test)\n",
        "\n",
        "# Remove rows with NaN values created by lagging (keep your fillna approach)\n",
        "train.dropna(inplace=True)\n",
        "test.fillna(test.mean(), inplace=True)  # For test set, fill remaining NaNs with mean\n",
        "\n",
        "# Optional: convert to float32 for memory efficiency\n",
        "train = train.astype(np.float32)\n",
        "test = test.astype(np.float32)\n",
        "\n",
        "# Your existing variable assignments (keeping exactly as you had them)\n",
        "X_train = train.drop(['pm2.5', 'No'], axis=1).values \n",
        "y_train = train['pm2.5'].values \n",
        "\n",
        "# Reshape data for LSTM input\n",
        "# LSTM models require data in the shape (samples, timesteps, features).\n",
        "# Here, the data is reshaped to add a \"timesteps\" dimension.\n",
        "X_train = np.expand_dims(X_train, axis=1)\n",
        "\n",
        "print(f\"Original features: {len([col for col in train.columns if col not in ['pm2.5', 'No']])} -> Enhanced features: {X_train.shape[2]}\")\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Target shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKndkdRuty1C"
      },
      "source": [
        "# Separate features and target\n",
        "\n",
        "- Feel free to trop any non-essential columns like that you think might not contribute to modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QETLRAo_tvQH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyP2mDjruG9R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d488782wuR2W"
      },
      "source": [
        "# Build model\n",
        "\n",
        "Below is a simple LSTM model. Your task is to experiment with different parameters like, numbers of layers, units, activation functions, and optimizers, etc to get the best performing model. Experiment with other optimizers (e.g., SGD) or hyperparameters to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "mfx2LPHxq5fG",
        "outputId": "a5eab018-edc3-4ca5-f5f9-e896e2cbd0a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lscblack/miniconda3/envs/ml-gpu/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_24      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">217</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,728</span> │ input_layer_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_69          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_70          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_41    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ dropout_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ bidirectional_41… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_71          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_42    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ dropout_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ bidirectional_42… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_72          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│                     │                   │            │ dropout_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_43    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">123,648</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bidirectional_43… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_73          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ leaky_re_lu_23      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ leaky_re_lu_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_74          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ leaky_re_lu_24      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ leaky_re_lu_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_75          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ leaky_re_lu_25      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_76          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dropout_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_24      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m217\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m41,728\u001b[0m │ input_layer_24[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m256\u001b[0m │ conv1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_69          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │     \u001b[38;5;34m24,704\u001b[0m │ dropout_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m512\u001b[0m │ conv1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_70          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_41    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m263,168\u001b[0m │ dropout_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,024\u001b[0m │ bidirectional_41… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_71          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_42    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m394,240\u001b[0m │ dropout_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m1,024\u001b[0m │ bidirectional_42… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_72          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│                     │                   │            │ dropout_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_43    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │    \u001b[38;5;34m123,648\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m512\u001b[0m │ bidirectional_43… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_73          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ leaky_re_lu_23      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ leaky_re_lu_23[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_74          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ leaky_re_lu_24      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ leaky_re_lu_24[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_75          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ leaky_re_lu_25      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_52[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_76          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_25[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dropout_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">878,465</span> (3.35 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m878,465\u001b[0m (3.35 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">876,417</span> (3.34 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m876,417\u001b[0m (3.34 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> (8.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,048\u001b[0m (8.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.layers import Bidirectional, LeakyReLU, GRU\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# =============================\n",
        "# STANDARDIZE DATA\n",
        "# =============================\n",
        "num_samples, timesteps, num_features = X_train.shape\n",
        "\n",
        "X_train_flat = X_train.reshape(-1, num_features)\n",
        "scaler = StandardScaler().fit(X_train_flat)\n",
        "X_train_scaled_flat = scaler.transform(X_train_flat)\n",
        "X_train = X_train_scaled_flat.reshape(num_samples, timesteps, num_features)\n",
        "\n",
        "# =============================\n",
        "# FIXED DEEP MODEL ARCHITECTURE\n",
        "# =============================\n",
        "def create_deep_pattern_capturing_model(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    \n",
        "    # Initial convolutional layers for local pattern extraction\n",
        "    x = Conv1D(64, kernel_size=3, padding='same', activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    \n",
        "    x = Conv1D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    # x = MaxPooling1D(pool_size=2)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    # First LSTM layer\n",
        "    lstm1 = Bidirectional(LSTM(128, return_sequences=True, \n",
        "                             kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))(x)\n",
        "    lstm1 = BatchNormalization()(lstm1)\n",
        "    lstm1 = Dropout(0.4)(lstm1)\n",
        "    \n",
        "    # Second LSTM layer with matching dimensions\n",
        "    lstm2 = Bidirectional(LSTM(128, return_sequences=True,  # Same units for residual connection\n",
        "                             kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)))(lstm1)\n",
        "    lstm2 = BatchNormalization()(lstm2)\n",
        "    lstm2 = Dropout(0.4)(lstm2)\n",
        "    \n",
        "    # Residual connection with matching dimensions\n",
        "    if lstm1.shape[-1] != lstm2.shape[-1]:\n",
        "        residual = Conv1D(lstm2.shape[-1], kernel_size=1, padding='same')(lstm1)\n",
        "    else:\n",
        "        residual = lstm1\n",
        "    \n",
        "    x = tf.keras.layers.add([lstm2, residual])\n",
        "    \n",
        "    # GRU layer\n",
        "    gru = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "    gru = BatchNormalization()(gru)\n",
        "    gru = Dropout(0.3)(gru)\n",
        "    \n",
        "    # Global pooling\n",
        "    pooled = GlobalAveragePooling1D()(gru)\n",
        "    \n",
        "    # Dense layers with regularization\n",
        "    x = Dense(128, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(pooled)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    x = Dense(64, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    \n",
        "    x = Dense(32)(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    # Output layer\n",
        "    outputs = Dense(1)(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Alternative simpler architecture if the above still has issues\n",
        "def create_robust_model(input_shape):\n",
        "    model = Sequential([\n",
        "        # Convolutional layers for pattern extraction\n",
        "        Conv1D(64, kernel_size=3, padding='same', activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        # MaxPooling1D(pool_size=1),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        Conv1D(128, kernel_size=3, padding='same', activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        \n",
        "        # Bidirectional LSTM layers\n",
        "        Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        \n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        \n",
        "        # GRU layer\n",
        "        Bidirectional(GRU(32, return_sequences=False)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        # Dense layers\n",
        "        Dense(128, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4)),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        \n",
        "        Dense(64),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        \n",
        "        Dense(32),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.3),\n",
        "        \n",
        "        # Output layer\n",
        "        Dense(1)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Create model - try the simpler version first\n",
        "try:\n",
        "    model = create_deep_pattern_capturing_model((X_train.shape[1], X_train.shape[2]))\n",
        "except Exception as e:\n",
        "    print(f\"Complex model failed: {e}\")\n",
        "    print(\"Creating robust model instead...\")\n",
        "    model = create_robust_model((X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "# =============================\n",
        "# OPTIMIZER WITH GRADIENT CLIPPING\n",
        "# =============================\n",
        "optimizer = Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-7,\n",
        "    clipnorm=1.0,\n",
        "    # clipvalue=0.5\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='mse',\n",
        "    metrics=['mae', 'mse']\n",
        ")\n",
        "\n",
        "# =============================\n",
        "# ENHANCED CALLBACKS\n",
        "# =============================\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=20,\n",
        "        restore_best_weights=True,\n",
        "        min_delta=0.001,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1,\n",
        "        cooldown=2\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        \"best_deep_pattern_model.h5\",\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# =============================\n",
        "# MODEL SUMMARY\n",
        "# =============================\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM0Xuq7XvdTZ",
        "outputId": "b6df9dee-acfd-416b-d50e-ab9b40201c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4568.1562 - mae: 46.2903 - mse: 4567.7988\n",
            "Epoch 1: val_loss improved from 4114.60303 to 4017.32153, saving model to best_deep_pattern_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 23ms/step - loss: 4656.0732 - mae: 46.3849 - mse: 4655.7153 - val_loss: 4017.3215 - val_mae: 41.5449 - val_mse: 4016.9519 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4336.2373 - mae: 45.2629 - mse: 4335.8662\n",
            "Epoch 2: val_loss did not improve from 4017.32153\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 4506.0151 - mae: 45.6047 - mse: 4505.6401 - val_loss: 4044.1177 - val_mae: 42.0955 - val_mse: 4043.7341 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4365.1489 - mae: 45.2666 - mse: 4364.7656\n",
            "Epoch 3: val_loss improved from 4017.32153 to 3949.99048, saving model to best_deep_pattern_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 23ms/step - loss: 4340.2700 - mae: 44.7236 - mse: 4339.8843 - val_loss: 3949.9905 - val_mae: 41.8412 - val_mse: 3949.5918 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m1148/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4181.3760 - mae: 44.4383 - mse: 4180.9775\n",
            "Epoch 4: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 4244.4570 - mae: 44.3792 - mse: 4244.0532 - val_loss: 4170.8760 - val_mae: 42.0875 - val_mse: 4170.4668 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4003.9548 - mae: 43.2413 - mse: 4003.5437\n",
            "Epoch 5: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 4116.9224 - mae: 43.5894 - mse: 4116.5103 - val_loss: 4071.4595 - val_mae: 41.6480 - val_mse: 4071.0388 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3929.8271 - mae: 43.1949 - mse: 3929.4016\n",
            "Epoch 6: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - loss: 4068.2769 - mae: 43.3846 - mse: 4067.8433 - val_loss: 4332.1997 - val_mae: 43.0413 - val_mse: 4331.7627 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3920.3950 - mae: 42.9048 - mse: 3919.9551\n",
            "Epoch 7: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 22ms/step - loss: 3966.3640 - mae: 42.8347 - mse: 3965.9199 - val_loss: 4141.8135 - val_mae: 42.8556 - val_mse: 4141.3643 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m1147/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3858.0386 - mae: 42.2938 - mse: 3857.5867\n",
            "Epoch 8: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 22ms/step - loss: 3945.6677 - mae: 42.5199 - mse: 3945.2109 - val_loss: 3972.6091 - val_mae: 42.1745 - val_mse: 3972.1445 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m1147/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3712.0498 - mae: 41.7270 - mse: 3711.5828\n",
            "Epoch 9: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 24ms/step - loss: 3789.8271 - mae: 41.8054 - mse: 3789.3562 - val_loss: 4106.5376 - val_mae: 42.3467 - val_mse: 4106.0635 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m1148/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3659.2664 - mae: 41.7323 - mse: 3658.7878\n",
            "Epoch 10: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 26ms/step - loss: 3767.3875 - mae: 41.8643 - mse: 3766.9050 - val_loss: 4216.5571 - val_mae: 42.6527 - val_mse: 4216.0693 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3681.0508 - mae: 41.6589 - mse: 3680.5571\n",
            "Epoch 11: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 3708.9246 - mae: 41.4378 - mse: 3708.4275 - val_loss: 4120.6982 - val_mae: 42.0916 - val_mse: 4120.1953 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3546.5056 - mae: 41.1606 - mse: 3545.9990\n",
            "Epoch 12: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 26ms/step - loss: 3607.8894 - mae: 41.0798 - mse: 3607.3799 - val_loss: 4232.2578 - val_mae: 42.4653 - val_mse: 4231.7407 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m1148/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3546.5320 - mae: 40.7535 - mse: 3546.0125\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 26ms/step - loss: 3620.1970 - mae: 40.6691 - mse: 3619.6772 - val_loss: 4174.8276 - val_mae: 41.8236 - val_mse: 4174.2964 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3423.6562 - mae: 40.3251 - mse: 3423.1257\n",
            "Epoch 14: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 26ms/step - loss: 3513.2600 - mae: 40.3146 - mse: 3512.7278 - val_loss: 4180.6118 - val_mae: 42.0258 - val_mse: 4180.0801 - learning_rate: 2.5000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3225.7581 - mae: 39.1907 - mse: 3225.2234\n",
            "Epoch 15: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 3362.1155 - mae: 39.4277 - mse: 3361.5818 - val_loss: 4161.1758 - val_mae: 42.1027 - val_mse: 4160.6382 - learning_rate: 2.5000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m1148/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3249.8835 - mae: 39.2283 - mse: 3249.3438\n",
            "Epoch 16: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 3291.4355 - mae: 39.0959 - mse: 3290.8967 - val_loss: 4204.7944 - val_mae: 42.5302 - val_mse: 4204.2539 - learning_rate: 2.5000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3242.5737 - mae: 39.4661 - mse: 3242.0317\n",
            "Epoch 17: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 3292.6528 - mae: 39.2081 - mse: 3292.1082 - val_loss: 4280.1953 - val_mae: 42.4610 - val_mse: 4279.6494 - learning_rate: 2.5000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m1148/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3172.7034 - mae: 39.0732 - mse: 3172.1594\n",
            "Epoch 18: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 3266.5886 - mae: 39.1390 - mse: 3266.0459 - val_loss: 4196.7344 - val_mae: 42.6970 - val_mse: 4196.1870 - learning_rate: 2.5000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3105.3425 - mae: 38.7180 - mse: 3104.7937\n",
            "Epoch 19: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 24ms/step - loss: 3249.4514 - mae: 38.9157 - mse: 3248.9019 - val_loss: 4212.2075 - val_mae: 42.3712 - val_mse: 4211.6558 - learning_rate: 2.5000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3115.7378 - mae: 38.5298 - mse: 3115.1846\n",
            "Epoch 20: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 3208.1992 - mae: 38.6757 - mse: 3207.6438 - val_loss: 4212.9609 - val_mae: 42.1743 - val_mse: 4212.4062 - learning_rate: 2.5000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3019.0500 - mae: 38.2794 - mse: 3018.4934\n",
            "Epoch 21: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 25ms/step - loss: 3166.1965 - mae: 38.5595 - mse: 3165.6379 - val_loss: 4223.1846 - val_mae: 42.2481 - val_mse: 4222.6255 - learning_rate: 2.5000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m1149/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3097.4421 - mae: 38.4274 - mse: 3096.8811\n",
            "Epoch 22: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 25ms/step - loss: 3195.3533 - mae: 38.5566 - mse: 3194.7866 - val_loss: 4152.5649 - val_mae: 42.3193 - val_mse: 4152.0044 - learning_rate: 2.5000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3139.8025 - mae: 38.6950 - mse: 3139.2390\n",
            "Epoch 23: val_loss did not improve from 3949.99048\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 52ms/step - loss: 3228.7134 - mae: 38.6449 - mse: 3228.1497 - val_loss: 4358.5220 - val_mae: 43.0055 - val_mse: 4357.9585 - learning_rate: 2.5000e-04\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 3.\n",
            "Model training completed with early stopping and learning rate scheduling\n"
          ]
        }
      ],
      "source": [
        "# Train the model with professional configuration\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,  # Use 20% of training data for validation\n",
        "    epochs=200,            # Increased epochs with early stopping\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks,   # Use the defined callbacks for optimization\n",
        "    verbose=1,             # Show progress bar\n",
        "    shuffle=True         # Important: Don't shuffle time series data\n",
        ")\n",
        "print(\"Model training completed with early stopping and learning rate scheduling\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "NKxlO7SmxFpU",
        "outputId": "5bd92101-7840-44f2-eda6-2bf10a1680f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m958/958\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Training Loss (MSE): 3237.67822265625\n"
          ]
        }
      ],
      "source": [
        "# Calculate training loss\n",
        "train_predictions = model.predict(X_train)\n",
        "train_loss = np.mean((y_train - train_predictions.flatten())**2)\n",
        "\n",
        "# Plot training loss\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')  # Training loss during epochs\n",
        "plt.axhline(y=train_loss, color='blue', linestyle='--', label='Final rain Loss')  # Final training loss\n",
        "plt.title('Loss on Training Data')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final Training Loss (MSE): {train_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Final Training Loss (MSE): 3183.20458984375\n",
        "\n",
        "Final Training Loss (MSE): 3245.11181640625\n",
        "\n",
        "final traing 3295.55712890625\n",
        "\n",
        "Final Training Loss (MSE): 5518.2392578125\n",
        "\n",
        "Final Training Loss (MSE): 5740.1162109375\n",
        "\n",
        "Final Training Loss (MSE): 5905.39892578125\n",
        "\n",
        "Final Training Loss (MSE): 7489.71875\n",
        "\n",
        "Final Training Loss (MSE): 10908.271484375\n",
        "\n",
        "Final Training Loss (MSE): 7389.98681640625 (0.01)\n",
        "\n",
        "Final Training Loss (MSE): 6858.7236328125\n",
        "\n",
        "Final Training Loss (MSE): 7189.4912109375 ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrw_e7OVwe6R",
        "outputId": "9a7966e6-fccf-409e-b3e4-c6ba968d610e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "submission system ready\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def save_submission(predictions, experiment_name, test_index, notes=\"\"):\n",
        "    \"\"\"\n",
        "    Save model predictions to CSV in a structured format compatible with Kaggle.\n",
        "    \n",
        "    Args:\n",
        "        predictions (array-like): Model predictions.\n",
        "        experiment_name (str): Name/ID of the experiment.\n",
        "        test_index (pd.Index or pd.DatetimeIndex): Index for test data rows.\n",
        "        notes (str, optional): Any additional notes to track.\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (fixed_filename, submission DataFrame)\n",
        "    \"\"\"\n",
        "    os.makedirs('submissions', exist_ok=True)\n",
        "    \n",
        "    # Ensure predictions are proper format, non-negative, integer, and NaN-safe\n",
        "    predictions = np.nan_to_num(np.maximum(np.array(predictions).flatten(), 0))\n",
        "    predictions = np.round(predictions).astype(int)\n",
        "    \n",
        "    # Convert test index to datetime strings with no leading zero in hour\n",
        "    row_ids = pd.to_datetime(test_index).strftime('%Y-%m-%d %-H:%M:%S')\n",
        "    \n",
        "    submission = pd.DataFrame({\n",
        "        'row ID': row_ids,\n",
        "        'pm2.5': predictions\n",
        "    })\n",
        "    \n",
        "    # Sort by 'row ID' for consistency\n",
        "    submission = submission.sort_values(by='row ID')\n",
        "    \n",
        "    # Fixed filename for Kaggle submission\n",
        "    fixed_filename = 'submissions/subm_fixed.csv'\n",
        "    submission.to_csv(fixed_filename, index=False)\n",
        "    \n",
        "    # Timestamped file for tracking experiments\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    tracking_filename = f'submissions/{timestamp}_{experiment_name}.csv'\n",
        "    submission.to_csv(tracking_filename, index=False)\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(f\"Submission saved: {fixed_filename}\")\n",
        "    print(f\"Predictions - Min: {predictions.min()}, Max: {predictions.max()}, Mean: {predictions.mean():.1f}\")\n",
        "    if notes:\n",
        "        print(f\"Notes: {notes}\")\n",
        "    \n",
        "    return fixed_filename, submission\n",
        "\n",
        "print(\"submission system ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
